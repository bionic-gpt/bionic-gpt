services:

  llm-api:
    image: litellm/ollama
    ports:
      - "3000:8000"