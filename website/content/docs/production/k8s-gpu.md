+++
title = "K8s and an Inference Engine"
weight = 80
sort_by = "weight"
+++

If you have a Kubernetes cluster with a GPU then this section is for you.

We recommend you run [Hugging Face TGI](https://github.com/huggingface/text-generation-inference) it's what Hugging Face are using in production and it's geared up for batch processing of requests for the best performance.

