+++
title = "Apple Silicon OSX"
weight = 40
sort_by = "weight"
+++

BionicGPT doesn't work out of the box on Apple Silicon.

We have'nt found an optimal solution for running on M series Macs so far.

There's is a way to get good performance using [LocalAI](https://localai.io/) they have a way to [build an executable](https://localai.io/basics/build/) for Apple Silicon that should give great performance for inference.

If you try  this, or know an easier way please let us know so we can update the documentation.