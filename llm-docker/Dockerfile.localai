FROM quay.io/go-skynet/local-ai:v1.30.0

RUN mkdir /build/models

# LLama 2 7b Chat
RUN wget https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf -O /build/models/llama-2-7b-chat

# This model allows us to use the embeddings API
RUN wget https://huggingface.co/skeskinen/ggml/resolve/main/all-MiniLM-L6-v2/ggml-model-q4_0.bin -O models/bert

COPY embeddings.yaml /build/models
