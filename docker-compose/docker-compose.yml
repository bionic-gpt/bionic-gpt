# Do not expose this configuration to the internet. This is an
# example configuration so that you can try out Bionic GPT.
#
# This is NOT a production configuration.
services:

  llm-api:
    image: ghcr.io/bionic-gpt/llama-2-7b-chat:1.0.5
    platform: linux/amd64

  embeddings-api:
    image: ghcr.io/bionic-gpt/bionicgpt-embeddings-api:cpu-0.6
    platform: linux/amd64

  # Document parsing, OCR and chunking.
  # Image tagged with the short commit hash (e.g. fbc7a69) for each pust to main
  unstructured:
    image: downloads.unstructured.io/unstructured-io/unstructured-api:4ffd8bc
    platform: linux/amd64

  # We use Oauth2 Proxy as the interface to our OIDC provider
  oauth2-proxy:
    image: quay.io/oauth2-proxy/oauth2-proxy:v7.5.1
    platform: linux/amd64
    environment:
      OAUTH2_PROXY_HTTP_ADDRESS: 0.0.0.0:7800
      OAUTH2_PROXY_COOKIE_SECRET: OQINaROshtE9TcZkNAm-5Zs2Pv3xaWytBmc5W7sPX7w=
      OAUTH2_PROXY_EMAIL_DOMAINS: "*"
      OAUTH2_PROXY_COOKIE_SECURE: "false"
      OAUTH2_PROXY_UPSTREAMS: http://app:7703
      OAUTH2_PROXY_UPSTREAMS_TIMEOUT: 600s
      OAUTH2_PROXY_CLIENT_SECRET: 69b26b08-12fe-48a2-85f0-6ab223f45777
      OAUTH2_PROXY_CLIENT_ID: bionic-gpt
      OAUTH2_PROXY_REDIRECT_URL: http://localhost:7800/oauth2/callback
      OAUTH2_PROXY_OIDC_ISSUER_URL: http://keycloak:7810/realms/bionic-gpt
      OAUTH2_PROXY_INSECURE_OIDC_SKIP_ISSUER_VERIFICATION: "true"
      OAUTH2_PROXY_INSECURE_OIDC_ALLOW_UNVERIFIED_EMAIL: "true"
      OAUTH2_PROXY_PROVIDER: oidc
      OAUTH2_PROXY_PROVIDER_DISPLAY_NAME: Keycloak
      OAUTH2_PROXY_AUTH_LOGGING: "true"
      OAUTH2_PROXY_SKIP_PROVIDER_BUTTON: "true"
      OAUTH2_PROXY_WHITELIST_DOMAINS: "localhost:7810"
      OAUTH2_PROXY_SKIP_AUTH_ROUTES:  "^/(v1|static)/.*"
    restart: unless-stopped
    ports:
      - 7800:7800
    depends_on:
      keycloak:
        condition: service_healthy

  # We support Open ID Connect. In this case we're using Keycloak
  # But you can use your own identityt provider.
  keycloak:
    image: ghcr.io/bionic-gpt/bionicgpt-keycloak:1.6.4
    platform: linux/amd64
    environment:
      KC_DB: postgres
      KC_DB_PASSWORD: testpassword
      KC_DB_USERNAME: postgres
      KC_DB_URL: jdbc:postgresql://postgres/keycloak
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: Pa55w0rd
      KC_HEALTH_ENABLED: "true"
    command:
      - "start-dev"
      - "--import-realm"
      - "--http-port=7810"
      - "--proxy=edge"
      - "--hostname=localhost:7810"
    ports:
      - 7810:7810
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/127.0.0.1/7810;echo -e \"GET /health/ready HTTP/1.1\r\nhost: http://localhost\r\nConnection: close\r\n\r\n\" >&3;grep \"HTTP/1.1 200 OK\" <&3"]
      interval: 10s
      timeout: 5s
      retries: 10
    depends_on:
      postgres:
        condition: service_healthy

  # Postgres pre-loaded with pgVector
  # To connect outside docker `docker compose exec postgres psql -U postgres`
  postgres:
    image: ankane/pgvector
    platform: linux/amd64
    environment:
      POSTGRES_PASSWORD: testpassword
      POSTGRES_USER: postgres
      POSTGRES_DB: keycloak
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Sets up our database tables
  migrations:
    image: ghcr.io/bionic-gpt/bionicgpt-db-migrations:1.6.4
    platform: linux/amd64
    environment:
      DATABASE_URL: postgresql://postgres:testpassword@postgres:5432/bionic-gpt?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy
  
  # Parses documents into chunks and creates embeddings.
  pipeline-job:
    image: ghcr.io/bionic-gpt/bionicgpt-pipeline-job:1.6.4
    platform: linux/amd64
    environment:
      EMBEDDINGS_API_ENDPOINT: http://embeddings-api:80/embeddings
      APP_DATABASE_URL: postgresql://bionic_application:testpassword@postgres:5432/bionic-gpt?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
  
  # Our axum server delivering our user interface
  app:
    image: ghcr.io/bionic-gpt/bionicgpt:1.6.4
    platform: linux/amd64
    environment:
      COMMUNITY_EDITION: "true"
      EMBEDDINGS_API_ENDPOINT: http://embeddings-api:80/embeddings
      LOGOUT_URL: http://localhost:7810/realms/bionic-gpt/protocol/openid-connect/logout?post_logout_redirect_uri=http://localhost:7800&client_id=bionic-gpt
      APP_DATABASE_URL: postgresql://bionic_application:testpassword@postgres:5432/bionic-gpt?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully

volumes:
  ollama: