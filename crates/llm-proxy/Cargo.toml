[package]
name = "llm-proxy"
version = "0.1.0"
edition = "2021"

[lib]
path = "lib.rs"

[dependencies]
db = { path = "../db" }
embeddings-api = { path = "../embeddings-api" }
integrations = { path = "../integrations" }
openai-api = { path = "../openai-api" }

axum = { workspace = true, features = ["multipart"] }
axum-extra = { workspace = true, features = ["form", "typed-routing", "cookie"] }
tokio = { version = "1", features = ["rt-multi-thread"] }
http = "1"
tokio-stream = "0.1"
reqwest = { workspace = true, default-features = false, features = ["stream", "json", "rustls"] }
serde_json = { version = "1" }
serde = { version = "1", features = ["derive"] }
tracing = { version = "0.1" }
tower-http = { workspace = true, features = ["fs", "cors"] }
async-trait = "0.1"

base64.workspace = true

[dev-dependencies]
time = "0.3.36"
