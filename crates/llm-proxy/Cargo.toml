[package]
name = "llm-proxy"
version = "0.1.0"
edition = "2021"

[lib]
path = "lib.rs"

[dependencies]
db = { path = "../db" }
embeddings-api = { path = "../embeddings-api" }
integrations = { path = "../integrations" }
openai-api = { path = "../openai-api" }

axum = { workspace = true, features = ["multipart"] }
axum-extra = { workspace = true, features = ["form", "typed-routing", "cookie"] }
tokio = { workspace = true, features = ["rt-multi-thread"] }
http.workspace = true
tokio-stream = "0.1"
reqwest = { workspace = true, default-features = false, features = ["stream", "json", "rustls"] }
serde_json.workspace = true
serde = { workspace = true, features = ["derive"] }
tracing.workspace = true
tower-http = { workspace = true, features = ["fs", "cors"] }
async-trait.workspace = true

base64.workspace = true

[dev-dependencies]
time.workspace = true
