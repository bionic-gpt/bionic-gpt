Bionic-GPT Local Edition allows you to run Generative AI on your laptop.

If you're already thinking about deploying Bionic for multiple users you may want to get started with the enterprise edition which is more robust and secure.

Bionic-GPT can run on modest hardware (16GB ram) and then scale into more powerful hardware when required. For example 70B running across multiple GPU cards.

We're open source. If you have any suggestions, recommendations are just have any questions you can either [contact us](/contact) or raise an issue on our github.

![Alt text](/landing-page/bionic-console.png "Start Screen")

## LLama 3 8B

For installations on modest hardware we run a quantized model with 8 billion parameters.

However typically larger models give better results and if you have access to a model with for example 70 billion parameters you'll get some great results.

We still believe this is a great way to start to look at the ways LLM's can help out in your company. We've tried to minimise the time it takes to go from idea to practical proof of concept.